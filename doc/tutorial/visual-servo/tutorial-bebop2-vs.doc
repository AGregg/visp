/**

\page tutorial-bebop2-vs Tutorial: Visual-servoing with Parrot Bebop 2 drone 
\tableofcontents

\section bebop2_intro Introduction

This tutorial explains how to do an image-based servoing with a Parrot Bebop 2 drone using Ubuntu or OSX.

\image html img-bebop2.jpg

\section bebop2_prereq Prerequisites

The following material is necessary:
- Parrot Bebop 2 drone
- An AprilTag from 36h11 family that will serve as target for the visual servoing. \ref franka_prereq_target. 

ViSP must be built with OpenCV support if you want to get the video streamed by the drone, which needs to be decoded.

\note Before continuing, we recommend that you succeed to complete \ref tutorial-detection-apriltag.

\subsection bebop2_prereq_arsdk3 Parrot ARSDK3 installation
In order to use Parrot Bebop 2 drone with ViSP, you first need to install Parrot's SDK <a href="https://developer.parrot.com/docs/SDK3/">ARDroneSDK3</a>.

To install ARSDK3 for ViSP, follow these steps (as seen <a href="https://developer.parrot.com/docs/SDK3/#go-deeper">here</a>) : \n\n

<b>On Ubuntu (tested on 18.04) and OSX (tested on macOS Mojave 10.14.5)</b>\n
1 - Get the SDK source code :
- Create a workspace.
\code
    $ cd ${VISP_WS}
    $ mkdir ARDroneSDK3 && cd ARDroneSDK3
\endcode
- Initialize the repo.
\code
    $ sudo apt  install repo
    $ repo init -u https://github.com/Parrot-Developers/arsdk_manifests.git -m release.xml
\endcode
- You can then download all the repositories automatically, by executing the following command.
\code
    $ repo sync
\endcode

2 - Build the SDK :
- Install required 3rd parties:
\note Doesn't seem to be needed on OSX.

\code
$ sudo apt-get install git build-essential autoconf libtool libavahi-client-dev libavcodec-dev libavformat-dev libswscale-dev libncurses5-dev mplayer
\endcode
- Build :
\code
$ ./build.sh -p arsdk-native -t build-sdk -j
\endcode
The output will be located in `${VISP_WS}/ARDroneSDK3/out/arsdk-native/staging/usr`

3 - In order for ViSP to find ARDroneSDK3, set ARSDK_DIR environment variable :
\code
$ export ARSDK_DIR=${VISP_WS}/ARDroneSDK3
\endcode
\n

\section bebop2_ibvs Image-based visual-servoing 
\subsection bebop2_ibvs_run Running the program

The next step is now to run the image-based visual servoing example implemented in servoBebop2.cpp. 
\n In this example, we use three visual features for the servoing :
- Image moment for normalized gravity center implemented in vpFeatureMomentGravityCenterNormalized, to center the drone along X and Y axes in front of the tag.
- Image moment for normalized area implemented in vpFeatureMomentAreaNormalized to control the distance between the drone and the tag.
- Horizontal vanishing points from the top and bottom tag sides implemented in vpFeatureVanishingPoint, to change the orientation of the drone based on the tag orientation.

\note  Before starting the program, the drone should be turned on and the computer connected to the drone WiFi, as shown in the following picture : \image html drone_connexion.png
\n
\warning CAUTION : It's is strongly recommended to use this program outside or in a large room with non-uniform flooring, as the drone uses a downward-facing camera for horizontal speed estimation.
\n If the surface under the drone is uniform, its movements will be inaccurate and dangerous.

If you built ViSP with OpenCV and Parrot ARSDK3 support, the corresponding binary is available in `/home/[...]/visp-ws/visp-build/example/servo-bebop2/`.
\code
    $ cd /home/[...]/visp-ws/visp-build/example/servo-bebop2
    $ ./servoBebop2 --tag_size 0.14
\endcode
\note Passing the tag size (in meters) as a parameter is required.

Run `./servoBebop2 --help` to see which are the command line options available.
- Adding option `--distance_to_tag 1.5` allows to specify the desired distance (in meters) to the tag for the drone servoing. Values between 0.5 and 2 are recommended.
- Adding option `--intrinsic ~/path-to-calibration-file/camera.xml` allows you to specify the intrinsic camera calibration parameters. This file can be obtained by completing \ref tutorial-calibration-intrinsic.
- Adding option `--hd_stream` enables HD 720p stream resolution. Increase range and accuracy of the tag detection, but increases latency and computation time.
\note Camera calibration settings are different for the two resolutions.\n  Make sure that if you pass custom intrinsic camera parameters, they were obtained with the correct resolution.
- Adding option `--verbose` or `-v` enables the display of information messages from the drone, and the velocity commands sent to the drone.

\n

The program will first connect to the drone, start the video streaming and decoding, and then the drone will take off and hover until it detects one (and one only) 36h11 AprilTag in the image.

\htmlonly <style>div.image img[src="img-drone_tag.jpg"]{width:600px;}</style> 
\endhtmlonly 
@image html img-drone_tag.jpg

\n
We then display the drone video stream with the features visible, and the error progression for each task :
\htmlonly <style>div.image img[src="drone_view.png"]{width:600px;}</style> 
\endhtmlonly 
@image html drone_view.png

\htmlonly <style>div.image img[src="servoing_task.png"]{width:600px;}</style> 
\endhtmlonly 
@image html servoing_task.png

In this graph :
- Xn corresponds to the error along X axis,
- Yn corresponds to the error along Y axis,
- an corresponds to the error along Z axis, which uses the surface area of the tag to compute the distance between the drone and the tag along this axis,
- atan(1/rho) corresponds to the error related to the top and bottom edges of the tag. This feature will make the drone move to ensure that the two lines remain parallel.

Clicking on the drone view display will make the drone land, safely disconnect everything and quit the program.
\n

\subsection bebop2_understanding Understanding the program
You can read \ref tutorial-ibvs to understand the basics, and then check the comments in servoBebop2.cpp for a more detailed explanation of the program.
TODO
*/
